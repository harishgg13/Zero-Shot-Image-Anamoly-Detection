{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6d87089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vitb8 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved KNN model!\n",
      "Anomaly Score: 23.142659759521486\n",
      "Anomaly Score: 52.44691390991211\n",
      "Good dir: /Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/good\n",
      "Anomaly dirs: ['/Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/crack', '/Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/print', '/Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/cut', '/Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/hole']\n",
      "\n",
      "Files in good: ['001.png', '000.png']\n",
      "Files in /Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/crack : ['002.png', '016.png', '017.png', '003.png', '015.png', '001.png', '000.png', '014.png', '010.png', '004.png', '005.png', '011.png', '007.png', '013.png', '012.png', '006.png', '008.png', '009.png']\n",
      "Files in /Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/print : []\n",
      "Files in /Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/cut : ['002.png', '016.png', '003.png', '015.png', '001.png', '000.png', '014.png', '010.png', '004.png', '005.png', '011.png', '007.png', '013.png', '012.png', '006.png', '008.png', '009.png']\n",
      "Files in /Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/hole : ['002.png', '016.png', '017.png', '003.png', '015.png', '001.png', '000.png', '014.png', '010.png', '004.png', '005.png', '011.png', '007.png', '013.png', '012.png', '006.png', '008.png', '009.png']\n",
      "\n",
      "Good images processed: 2\n",
      "Anomaly images processed: 53\n",
      "Total processed: 55\n",
      "\n",
      "AUC-ROC: 1.0\n",
      "AUC-PR : 1.0\n",
      "Best F1: 1.0000 at threshold 25.0510\n",
      "Precision: 1.0000, Recall: 1.0000\n",
      "\n",
      "Saved hazelnut_test_scores_knn.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "folder_path=\"/Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/train/good/\"\n",
    "path_os=os.listdir(folder_path)\n",
    "img_path=[folder_path+i for i in path_os]\n",
    "PIL_image=[Image.open(i).convert(\"RGB\") for i in img_path]\n",
    "\n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "model_name = \"facebook/dino-vitb8\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "encoder = AutoModel.from_pretrained(model_name)\n",
    "encoder.eval()\n",
    "\n",
    "import torch\n",
    "\n",
    "normal_embeddings = []\n",
    "\n",
    "for img in PIL_image:\n",
    "    x = transform(img)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = processor(images=x, return_tensors=\"pt\", do_rescale=False)\n",
    "        outputs = encoder(**inputs)\n",
    "\n",
    "    embedding = outputs.last_hidden_state[:, 0, :]   # CLS token\n",
    "    embedding = embedding.squeeze(0)                 # shape: (768,)\n",
    "    normal_embeddings.append(embedding)\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# Convert list of tensors â†’ 2D numpy array\n",
    "normal_embeddings_np = torch.stack(normal_embeddings).numpy()\n",
    "\n",
    "knn_hazelnut = NearestNeighbors(n_neighbors=5)\n",
    "knn_hazelnut.fit(normal_embeddings_np)\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(knn, \"knn_hazelnut_good_model.pkl\")\n",
    "print(\"Saved KNN model!\")\n",
    "\n",
    "# --- Load a Good-test image ---\n",
    "test_path = \"/Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/good/000.png\"\n",
    "img = Image.open(test_path).convert(\"RGB\")\n",
    "\n",
    "# --- Preprocess ---\n",
    "x = transform(img)\n",
    "\n",
    "# --- Get test embedding ---\n",
    "with torch.no_grad():\n",
    "    inputs = processor(images=x, return_tensors=\"pt\", do_rescale=False)\n",
    "    outputs = encoder(**inputs)\n",
    "\n",
    "test_embed = outputs.last_hidden_state[:, 0, :].squeeze(0)  # (768,)\n",
    "\n",
    "# --- Convert to numpy ---\n",
    "test_embed_np = test_embed.numpy().reshape(1, -1)\n",
    "\n",
    "# --- Compute distance using k-NN ---\n",
    "dist, _ = knn.kneighbors(test_embed_np)\n",
    "\n",
    "anomaly_score = dist.mean()\n",
    "print(\"Anomaly Score:\", anomaly_score)\n",
    "# --- Load a defective-test image ---\n",
    "test_path = \"/Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/crack/000.png\"\n",
    "img = Image.open(test_path).convert(\"RGB\")\n",
    "\n",
    "# --- Preprocess ---\n",
    "x = transform(img)\n",
    "\n",
    "# --- Get test embedding ---\n",
    "with torch.no_grad():\n",
    "    inputs = processor(images=x, return_tensors=\"pt\", do_rescale=False)\n",
    "    outputs = encoder(**inputs)\n",
    "\n",
    "test_embed = outputs.last_hidden_state[:, 0, :].squeeze(0)  # (768,)\n",
    "\n",
    "# --- Convert to numpy ---\n",
    "test_embed_np = test_embed.numpy().reshape(1, -1)\n",
    "\n",
    "# --- Compute distance using k-NN ---\n",
    "dist, _ = knn.kneighbors(test_embed_np)\n",
    "\n",
    "anomaly_score = dist.mean()\n",
    "print(\"Anomaly Score:\", anomaly_score)\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "\n",
    "# allowed image extensions\n",
    "valid_ext = [\".png\", \".jpg\", \".jpeg\", \".bmp\"]\n",
    "\n",
    "# paths\n",
    "test_root = \"/Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/\"\n",
    "good_dir = os.path.join(test_root, \"good\")\n",
    "\n",
    "# anomalies: any folder except 'good'\n",
    "anomaly_dirs = [\n",
    "    os.path.join(test_root, d)\n",
    "    for d in os.listdir(test_root)\n",
    "    if d != \"good\" and os.path.isdir(os.path.join(test_root, d))\n",
    "]\n",
    "\n",
    "# ---------- PRINT PATHS ----------\n",
    "print(\"Good dir:\", good_dir)\n",
    "print(\"Anomaly dirs:\", anomaly_dirs)\n",
    "\n",
    "print(\"\\nFiles in good:\", os.listdir(good_dir))\n",
    "for ad in anomaly_dirs:\n",
    "    print(\"Files in\", ad, \":\", os.listdir(ad))\n",
    "\n",
    "\n",
    "# helper to get embedding (returns numpy 1x768)\n",
    "def get_embed_from_pil(img_pil):\n",
    "    x = transform(img_pil)  # transform defined earlier\n",
    "    with torch.no_grad():\n",
    "        inputs = processor(images=x, return_tensors=\"pt\", do_rescale=False)\n",
    "        outputs = encoder(**inputs)\n",
    "    emb = outputs.last_hidden_state[:, 0, :].squeeze(0)  # (768,)\n",
    "    return emb.cpu().numpy().reshape(1, -1)\n",
    "\n",
    "\n",
    "# evaluate images\n",
    "scores = []\n",
    "labels = []\n",
    "paths = []\n",
    "\n",
    "count_good = 0\n",
    "count_anomaly = 0\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# GOOD images (label = 0)\n",
    "# -------------------------\n",
    "for fn in sorted(os.listdir(good_dir)):\n",
    "    if not any(fn.lower().endswith(ext) for ext in valid_ext):\n",
    "        continue\n",
    "\n",
    "    p = os.path.join(good_dir, fn)\n",
    "\n",
    "    try:\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    emb_np = get_embed_from_pil(img)\n",
    "    dist, _ = knn.kneighbors(emb_np)\n",
    "    score = dist.mean()\n",
    "\n",
    "    scores.append(float(score))\n",
    "    labels.append(0)\n",
    "    paths.append(p)\n",
    "\n",
    "    count_good += 1\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# ANOMALY images (label = 1)\n",
    "# -------------------------\n",
    "for ad in anomaly_dirs:\n",
    "    for fn in sorted(os.listdir(ad)):\n",
    "        if not any(fn.lower().endswith(ext) for ext in valid_ext):\n",
    "            continue\n",
    "\n",
    "        p = os.path.join(ad, fn)\n",
    "\n",
    "        try:\n",
    "            img = Image.open(p).convert(\"RGB\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        emb_np = get_embed_from_pil(img)\n",
    "        dist, _ = knn.kneighbors(emb_np)\n",
    "        score = dist.mean()\n",
    "\n",
    "        scores.append(float(score))\n",
    "        labels.append(1)\n",
    "        paths.append(p)\n",
    "\n",
    "        count_anomaly += 1\n",
    "\n",
    "\n",
    "# ---------- PRINT COUNTS ----------\n",
    "print(\"\\nGood images processed:\", count_good)\n",
    "print(\"Anomaly images processed:\", count_anomaly)\n",
    "print(\"Total processed:\", count_good + count_anomaly)\n",
    "\n",
    "\n",
    "# convert to numpy\n",
    "scores = np.array(scores)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# -------------------------\n",
    "# Compute performance metrics\n",
    "# -------------------------\n",
    "roc = roc_auc_score(labels, scores)\n",
    "pr = average_precision_score(labels, scores)\n",
    "\n",
    "# find best threshold by maximizing F1\n",
    "thresholds = np.linspace(scores.min(), scores.max(), 200)\n",
    "best_f1 = 0.0\n",
    "best_thresh = thresholds[0]\n",
    "best_prec = best_rec = 0.0\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (scores >= t).astype(int)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='binary', zero_division=0\n",
    "    )\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "        best_prec = prec\n",
    "        best_rec = rec\n",
    "\n",
    "# ---------- PRINT METRICS ----------\n",
    "print(\"\\nAUC-ROC:\", round(roc, 4))\n",
    "print(\"AUC-PR :\", round(pr, 4))\n",
    "print(f\"Best F1: {best_f1:.4f} at threshold {best_thresh:.4f}\")\n",
    "print(f\"Precision: {best_prec:.4f}, Recall: {best_rec:.4f}\")\n",
    "\n",
    "\n",
    "# save results\n",
    "df = pd.DataFrame({\"path\": paths, \"label\": labels, \"score\": scores})\n",
    "df.to_csv(\"hazelnut_test_scores_knn.csv\", index=False)\n",
    "print(\"\\nSaved hazelnut_test_scores_knn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e5dfebd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 23.142659759521486\n",
      "Prediction: GOOD\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def predict_image(path):\n",
    "    # load image\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    \n",
    "    # get embedding\n",
    "    emb_np = get_embed_from_pil(img)   # function defined earlier\n",
    "    \n",
    "    # kNN distance\n",
    "    dist, _ = knn.kneighbors(emb_np)\n",
    "    score = dist.mean()\n",
    "\n",
    "    # classification\n",
    "    if score < 25.1:\n",
    "        label = \"GOOD\"\n",
    "\n",
    "    elif 25.1 <= score < 27.5:\n",
    "        label = \"CUT\"\n",
    "\n",
    "    elif 27.5 <= score <= 37.5:\n",
    "        label = \"CUT or HOLE\"    # overlap area\n",
    "\n",
    "    elif 37.5 <= score <= 47.1:\n",
    "        label = \"CRACK or HOLE\"    # overlap area\n",
    "\n",
    "    elif score > 47.1:\n",
    "        label = \"CRACK\"\n",
    "\n",
    "\n",
    "    return score, label\n",
    "\n",
    "img_path = \"/Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/good/000.png\"\n",
    "\n",
    "score, label = predict_image(img_path)\n",
    "print(\"Score:\", score)\n",
    "print(\"Prediction:\", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f536b45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 42.9609489440918\n",
      "Prediction: CRACK or HOLE\n"
     ]
    }
   ],
   "source": [
    "img_path = \"/Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/crack/001.png\"\n",
    "\n",
    "score, label = predict_image(img_path)\n",
    "print(\"Score:\", score)\n",
    "print(\"Prediction:\", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5611dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "cut_score_list=[]\n",
    "cut_label_list=[]\n",
    "folder_path = \"/Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/cut/\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        score, label = predict_image(img_path)\n",
    "        cut_score_list.append(score)\n",
    "        label= 1 if label in [\"CUT\", \"CUT or HOLE\"] else 0\n",
    "        cut_label_list.append(label)\n",
    "\n",
    "crack_score_list=[]\n",
    "crack_label_list=[]\n",
    "folder_path = \"/Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/crack/\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        score, label = predict_image(img_path)\n",
    "        crack_score_list.append(score)\n",
    "        label= 1 if label in [\"CUT\", \"CRACK or HOLE\"] else 0\n",
    "        crack_label_list.append(label)\n",
    "\n",
    "good_score_list=[]\n",
    "good_label_list=[]\n",
    "folder_path = \"/Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/good/\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        score, label = predict_image(img_path)\n",
    "        good_score_list.append(score)\n",
    "        label=1 if label==\"GOOD\" else 0\n",
    "        good_label_list.append(label)\n",
    "\n",
    "hole_score_list=[]\n",
    "hole_label_list=[]\n",
    "folder_path = \"/Users/ggharish13/Data Science/Capstone Project/Final Project/Images/hazelnut/test/hole/\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        score, label = predict_image(img_path)\n",
    "        hole_score_list.append(score)\n",
    "        label=1 if label==\"CUT or HOLE\" else 0\n",
    "        hole_label_list.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f8f9ae57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut_score_list min= 26.14229965209961 cut_score_list max= 38.96882781982422\n",
      "crack_score_list min= 31.095760345458984 crack_score_list max= 61.11775894165039\n",
      "good_score_list min= 23.142659759521486 good_score_list max= 25.0428165435791\n",
      "hole_score_list min= 27.51972312927246 hole_score_list max= 47.1120246887207\n"
     ]
    }
   ],
   "source": [
    "print(\"cut_score_list min=\",min(cut_score_list),\"cut_score_list max=\",max(cut_score_list))\n",
    "print(\"crack_score_list min=\",min(crack_score_list),\"crack_score_list max=\",max(crack_score_list))\n",
    "print(\"good_score_list min=\",min(good_score_list),\"good_score_list max=\",max(good_score_list))\n",
    "print(\"hole_score_list min=\",min(hole_score_list),\"hole_score_list max=\",max(hole_score_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
